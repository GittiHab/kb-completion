{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "file_path_edges = './scifi/scifi_triples.txt'\n",
    "file_path_entities = './scifi/entity2id.txt'\n",
    "\n",
    "embedding_size = 300\n",
    "train_ratio = 0.7\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_file = open(file_path_edges, 'r')\n",
    "entities_file = open(file_path_entities, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = sum(1 for line in entities_file)\n",
    "# Read edges\n",
    "edges = {}\n",
    "classes = set()\n",
    "first = False\n",
    "for line in edges_file:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    \n",
    "    data = line.strip().split(\" \")\n",
    "    edge = (int(data[0]), int(data[1]))\n",
    "    \n",
    "    if len(data) < 3:\n",
    "        data.append(\"\")\n",
    "    classes.add(data[2])\n",
    "    if edge not in edges.keys():\n",
    "        edges[edge] = [int(data[2])]\n",
    "    else:\n",
    "        edges[edge].append(int(data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70617"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def multi_hot(types):\n",
    "    vec = np.zeros(len(classes))\n",
    "    x = True\n",
    "    for t in types:\n",
    "        x = False\n",
    "        vec[t] = 1\n",
    "    if x:\n",
    "        print(\":(\")\n",
    "    return vec\n",
    "\n",
    "def preprocess(pair, types):\n",
    "    x = np.array([pair[0]] + [pair[1]])\n",
    "    y = multi_hot(types)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "data = []\n",
    "for key in edges.keys():\n",
    "    x, y = preprocess(key, edges[key])\n",
    "    data.append(np.append(x, y))\n",
    "x_len = len(x)\n",
    "data = np.array(data).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in to training and test set\n",
    "np.random.shuffle(data)\n",
    "x = data[:, :x_len]\n",
    "y = data[:, x_len:]\n",
    "\n",
    "training_size = int(len(data) * train_ratio)\n",
    "\n",
    "x_train = x[:training_size]\n",
    "y_train = y[:training_size]\n",
    "x_test = x[training_size:]\n",
    "y_test = y[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49431, 21186)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_size = len(classes)\n",
    "classes_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='categorical_accuracy', min_delta=0, patience=2, verbose=0, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_distribution = np.sum(y_train.astype(np.float), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_distribution, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25406/49431 [==============>...............] - ETA: 17:56 - loss: 12.0212 - categorical_accuracy: 0.3457"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          callbacks = [],\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.around(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = np.sum(y_test.astype(np.float), axis=0)\n",
    "actual = np.sum(y_predicted, axis=0)\n",
    "actual[actual < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((expected - actual)/y_test.shape[0], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "def model(features, labels, mode, params, config):\n",
    "    bow_input = tf.reduce_mean(tf.one_hot(features, vocab_size), 1) # tf.placeholder(tf.float32, shape=(None, vocab_size), name=\"x\")\n",
    "    label = labels # tf.placeholder(tf.float32, shape=(None, classes_size), name=\"y\")\n",
    "    embedding = tf.Variable(tf.random_normal([embedding_size, vocab_size], stddev=0.1), name=\"embedding\")\n",
    "    parameters = tf.Variable(tf.random_normal([classes_size, embedding_size], stddev=0.1), name=\"weights\")\n",
    "    \n",
    "    prediction = tf.nn.softmax(\n",
    "                            tf.matmul(parameters,\n",
    "                                        tf.matmul(embedding, bow_input)))\n",
    "    \n",
    "    loss = -1 * tf.reduce_sum(\n",
    "        tf.matmul(label,\n",
    "                    tf.log(prediction)))\n",
    "    \n",
    "    optimizer = AdamOptimizer()\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=prediction, loss=loss, train_op=optimizer.minimize(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
