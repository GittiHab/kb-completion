{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_data(path):\n",
    "    file = open(path, 'r')\n",
    "    data = []\n",
    "    for line in file:\n",
    "        data.append(line.strip(\"\\n\").split())\n",
    "    return np.array(data)\n",
    "\n",
    "def load_embedding(path, skipFirst = True):\n",
    "    file = open(path, 'r')\n",
    "    ids = []\n",
    "    data = []\n",
    "    for line in file:\n",
    "        if skipFirst:\n",
    "            skipFirst = False\n",
    "            continue\n",
    "        embedding = line.strip(\"\\n\").split()\n",
    "        data.append(embedding)\n",
    "    return np.array(data).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'fb15k'\n",
    "train = load_file_data('data/'+dataset+'/train.txt')\n",
    "test = load_file_data('data/'+dataset+'/test.txt')\n",
    "valid = load_file_data('data/'+dataset+'/valid.txt')\n",
    "\n",
    "embeddings = load_embedding('data/'+dataset+'/embedding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y_split(data, embeddings):\n",
    "    embedding_frame = pd.DataFrame(embeddings, dtype='float64')\n",
    "    x_cols = embedding_frame.columns.values[1:]\n",
    "    embedding_frame[0] = embedding_frame[0].astype('int64')\n",
    "    \n",
    "    data_frame = pd.DataFrame(data=data, columns=['subject', 'object', 'relation'], dtype=np.int32)\n",
    "    counts = data_frame.groupby('subject').count()['relation']\n",
    "\n",
    "    y = counts.sort_index()\n",
    "    x = embedding_frame[embedding_frame[0].isin(data_frame['subject'].unique())].sort_values(by=0).reset_index(drop=True)[x_cols]\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This doesn't work... we need to count the number of edges in the whole dataset and then split it...\n",
    "x_train, y_train = x_y_split(train, embeddings)\n",
    "x_test, y_test = x_y_split(test, embeddings)\n",
    "x_valid, y_valid = x_y_split(valid, embeddings)\n",
    "\n",
    "x_train = pd.concat([x_train, x_valid])\n",
    "y_train = pd.concat([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 325.66836068773836\n",
      "AdaBoost 1173.4906017139929\n",
      "GradientBoost 379.880298928149\n"
     ]
    }
   ],
   "source": [
    "regressors = [\n",
    "    ('RandomForest', RandomForestRegressor(20, max_depth=2, random_state=0)),\n",
    "    ('AdaBoost', AdaBoostRegressor(random_state=0)),\n",
    "    ('GradientBoost', GradientBoostingRegressor(random_state=0))\n",
    "]\n",
    "\n",
    "for name, regr in regressors:\n",
    "    regr.fit(x_train, y_train)\n",
    "    print(name, sklearn.metrics.mean_squared_error(y_test, regr.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
